


<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="This is a notes generated by Mcdocs.">
      
      
      
        <meta name="author" content="ColorlessBoy">
      
      <link rel="shortcut icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-5.5.0">
    
    
      
        <title>The Margins Explanation For Boosting - Notes</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.b5d04df8.min.css">
      
        <link rel="stylesheet" href="../../assets/stylesheets/palette.9ab2c1f8.min.css">
      
      
        
        
        <meta name="theme-color" content="#3f51b5">
      
    
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style>
      
    
    
      <link rel="manifest" href="../../manifest.webmanifest" crossorigin="use-credentials">
    
    
    
      
    
    
  </head>
  
  
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#the-margins-explanation-for-boostings-effectiveness" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid" aria-label="Header">
    <a href="../.." title="Notes" class="md-header-nav__button md-logo" aria-label="Notes">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header-nav__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header-nav__title" data-md-component="header-title">
      
        <div class="md-header-nav__ellipsis">
          <span class="md-header-nav__topic md-ellipsis">
            Notes
          </span>
          <span class="md-header-nav__topic md-ellipsis">
            
              The Margins Explanation For Boosting
            
          </span>
        </div>
      
    </div>
    
      <label class="md-header-nav__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active">
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" data-md-component="search-reset" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header-nav__source">
        
<a href="https://github.com/colorlessboy/Notes/" title="前往 GitHub 仓库" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    ColorlessBoy/Notes
  </div>
</a>
      </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
        
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Notes" class="md-nav__button md-logo" aria-label="Notes">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    Notes
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/colorlessboy/Notes/" title="前往 GitHub 仓库" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    ColorlessBoy/Notes
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../.." title="介绍" class="md-nav__link">
      介绍
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2" checked>
    
    <label class="md-nav__link" for="nav-2">
      机器学习
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="机器学习" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        机器学习
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../01-EM/" title="EM" class="md-nav__link">
      EM
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../02-SVM/" title="SVM" class="md-nav__link">
      SVM
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../03-Rademacher/" title="Rademacher" class="md-nav__link">
      Rademacher
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../04-Regression/" title="Regression" class="md-nav__link">
      Regression
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../05-AdaBoost/" title="AdaBoost" class="md-nav__link">
      AdaBoost
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../06-PAC/" title="PAC" class="md-nav__link">
      PAC
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../07-KalmanFilter/" title="Kalman Filter" class="md-nav__link">
      Kalman Filter
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../08-Classification/" title="Classification" class="md-nav__link">
      Classification
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../09-PCA/" title="PCA" class="md-nav__link">
      PCA
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../10-NoFreeLunch/" title="No Free Lunch" class="md-nav__link">
      No Free Lunch
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../11-VCDimension/" title="VC Dimension" class="md-nav__link">
      VC Dimension
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../12-GenerationsOfBoosting/" title="Generation Of Boosting" class="md-nav__link">
      Generation Of Boosting
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        The Margins Explanation For Boosting
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 9h14V7H3v2m0 4h14v-2H3v2m0 4h14v-2H3v2m16 0h2v-2h-2v2m0-10v2h2V7h-2m0 6h2v-2h-2v2z"/></svg>
        </span>
      </label>
    
    <a href="./" title="The Margins Explanation For Boosting" class="md-nav__link md-nav__link--active">
      The Margins Explanation For Boosting
    </a>
    
      
<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </span>
      目录
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#finite-base-hypothesis-space" class="md-nav__link">
    Finite Base Hypothesis Space
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#infinite-base-hypothesis-spaces" class="md-nav__link">
    Infinite Base Hypothesis Spaces
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#rademacher" class="md-nav__link">
    基于 Rademacher 复杂度的分析
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#boosting-margin" class="md-nav__link">
    Boosting 对 Margin 分布的影响
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#marginboosting" class="md-nav__link">
    Margin最大化Boosting
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#weak-learnability" class="md-nav__link">
    Weak Learnability 的充分必要条件
  </a>
  
    <nav class="md-nav" aria-label="Weak Learnability 的充分必要条件">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    充分条件
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    必要条件
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../14-GameTheory/" title="Game Theory, Online Learning and Boosting" class="md-nav__link">
      Game Theory, Online Learning and Boosting
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3">
    
    <label class="md-nav__link" for="nav-3">
      强化学习
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="强化学习" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        强化学习
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-3-1" type="checkbox" id="nav-3-1">
    
    <label class="md-nav__link" for="nav-3-1">
      基础
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="基础" data-md-level="2">
      <label class="md-nav__title" for="nav-3-1">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        基础
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../RL/basis/01-MarkovChains/" title="Markov Chains" class="md-nav__link">
      Markov Chains
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../RL/basis/02-MDPs/" title="Markov Decision Processes" class="md-nav__link">
      Markov Decision Processes
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../RL/basis/03-PolicyEvaluation/" title="Policy Evaluation" class="md-nav__link">
      Policy Evaluation
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../RL/basis/04-PolicyImprovement/" title="Policy Improvement" class="md-nav__link">
      Policy Improvement
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-3-2" type="checkbox" id="nav-3-2">
    
    <label class="md-nav__link" for="nav-3-2">
      论文
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="论文" data-md-level="2">
      <label class="md-nav__title" for="nav-3-2">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        论文
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../RL/papers/EquivalenceBetweenPGandSQL/" title="Equivalence Between PG and SQL" class="md-nav__link">
      Equivalence Between PG and SQL
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../RL/papers/ACKTRandA2C/" title="ACKTR & A2C" class="md-nav__link">
      ACKTR & A2C
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../RL/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E6%91%98%E8%A6%81/" title="论文阅读摘要" class="md-nav__link">
      论文阅读摘要
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4">
    
    <label class="md-nav__link" for="nav-4">
      算法
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="算法" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        算法
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../Algorithms/01-%E6%9C%80%E9%95%BF%E9%80%92%E5%A2%9E%E5%AD%90%E5%BA%8F%E5%88%97/" title="最长递增子序列" class="md-nav__link">
      最长递增子序列
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../Algorithms/02-%E5%8C%BA%E9%97%B4%E8%B0%83%E5%BA%A6%E9%97%AE%E9%A2%98/" title="区间调度问题" class="md-nav__link">
      区间调度问题
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../Algorithms/03-%E8%A3%B4%E8%9C%80%E5%AE%9A%E7%90%86/" title="裴蜀定理" class="md-nav__link">
      裴蜀定理
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../Algorithms/04-%E5%89%AA%E7%BB%B3%E5%AD%90%E9%97%AE%E9%A2%98/" title="剪绳子问题" class="md-nav__link">
      剪绳子问题
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../Algorithms/05-%E6%AC%A7%E6%8B%89%E5%87%BD%E6%95%B0/" title="欧拉函数" class="md-nav__link">
      欧拉函数
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../Algorithms/06-%E8%93%84%E6%B0%B4%E6%B1%A0%E6%8A%BD%E6%A0%B7/" title="蓄水池抽样" class="md-nav__link">
      蓄水池抽样
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../Algorithms/07-%E9%87%8D%E7%BC%96%E7%A0%81%E6%8A%80%E5%B7%A7/" title="重编码技巧" class="md-nav__link">
      重编码技巧
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../Algorithms/08-%E6%94%BE%E6%9D%BE%E6%9D%A1%E4%BB%B6%E6%B3%95/" title="放松条件法" class="md-nav__link">
      放松条件法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../Algorithms/09-%E5%8D%95%E8%B0%83%E6%A0%88/" title="单调栈" class="md-nav__link">
      单调栈
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../Algorithms/10-%E6%9C%80%E9%95%BF%E5%85%A8%E6%8E%92%E5%88%97/" title="最长全排列" class="md-nav__link">
      最长全排列
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../Algorithms/11-%E5%BC%BA%E8%BF%9E%E9%80%9A%E5%88%86%E9%87%8F/" title="强连通分量" class="md-nav__link">
      强连通分量
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../Algorithms/12-%E5%A0%86%E6%8E%92%E5%BA%8F/" title="堆排序" class="md-nav__link">
      堆排序
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5">
    
    <label class="md-nav__link" for="nav-5">
      操作系统/6.S081
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="操作系统/6.S081" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        操作系统/6.S081
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../6.S081/Lab00-%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87/" title="Lab0-环境准备" class="md-nav__link">
      Lab0-环境准备
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../6.S081/Lab01-Xv6-and-Unix-utilities/" title="Lab1-Xv6 and Unix utilities" class="md-nav__link">
      Lab1-Xv6 and Unix utilities
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../6.S081/Lab02-System-Calls/" title="Lab2-System Calls" class="md-nav__link">
      Lab2-System Calls
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../6.S081/Lab03-Page-Tables/" title="Lab3-Page Tables" class="md-nav__link">
      Lab3-Page Tables
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../6.S081/Lab04-Traps/" title="Lab4-Traps" class="md-nav__link">
      Lab4-Traps
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../6.S081/Lab05-Xv6-Lazy-Allocation/" title="Lab5-Xv6-Lazy-Allocation" class="md-nav__link">
      Lab5-Xv6-Lazy-Allocation
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../6.S081/Lab06-Copy-on-Write/" title="Lab6-Copy-on-Write" class="md-nav__link">
      Lab6-Copy-on-Write
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../6.S081/Xv6%E7%9A%84%E8%B5%B7%E5%A7%8B%E9%99%B7%E9%98%B1%E6%9C%BA%E5%88%B6/" title="Xv6的起始陷阱机制" class="md-nav__link">
      Xv6的起始陷阱机制
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-6" type="checkbox" id="nav-6">
    
    <label class="md-nav__link" for="nav-6">
      Blog
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="Blog" data-md-level="1">
      <label class="md-nav__title" for="nav-6">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        Blog
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-6-1" type="checkbox" id="nav-6-1">
    
    <label class="md-nav__link" for="nav-6-1">
      子弹笔记
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="子弹笔记" data-md-level="2">
      <label class="md-nav__title" for="nav-6-1">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        子弹笔记
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../Blog/%E5%AD%90%E5%BC%B9%E7%AC%94%E8%AE%B0/%E5%AD%90%E5%BC%B9%E7%AC%94%E8%AE%B0-docker/" title="docker" class="md-nav__link">
      docker
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../Blog/%E5%AD%90%E5%BC%B9%E7%AC%94%E8%AE%B0/%E5%AD%90%E5%BC%B9%E7%AC%94%E8%AE%B0-gdb/" title="gdb" class="md-nav__link">
      gdb
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../Blog/%E5%AD%90%E5%BC%B9%E7%AC%94%E8%AE%B0/%E5%AD%90%E5%BC%B9%E7%AC%94%E8%AE%B0-git/" title="git" class="md-nav__link">
      git
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../Blog/%E5%AD%90%E5%BC%B9%E7%AC%94%E8%AE%B0/%E5%AD%90%E5%BC%B9%E7%AC%94%E8%AE%B0-makefile/" title="makefile" class="md-nav__link">
      makefile
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../Blog/%E5%AD%90%E5%BC%B9%E7%AC%94%E8%AE%B0/%E5%AD%90%E5%BC%B9%E7%AC%94%E8%AE%B0-shell/" title="shell" class="md-nav__link">
      shell
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../Blog/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" title="计算机网络" class="md-nav__link">
      计算机网络
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../Blog/%E8%99%9A%E6%8B%9F%E5%AE%B9%E5%99%A8Docker%E5%85%A5%E9%97%A8/" title="虚拟容器Docker入门" class="md-nav__link">
      虚拟容器Docker入门
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../Blog/vscode%E5%AF%B9markdown%E8%BF%9B%E8%A1%8C%E8%87%AA%E5%8A%A8%E6%8D%A2%E8%A1%8C/" title="vscode对markdown进行自动换行" class="md-nav__link">
      vscode对markdown进行自动换行
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </span>
      目录
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#finite-base-hypothesis-space" class="md-nav__link">
    Finite Base Hypothesis Space
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#infinite-base-hypothesis-spaces" class="md-nav__link">
    Infinite Base Hypothesis Spaces
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#rademacher" class="md-nav__link">
    基于 Rademacher 复杂度的分析
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#boosting-margin" class="md-nav__link">
    Boosting 对 Margin 分布的影响
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#marginboosting" class="md-nav__link">
    Margin最大化Boosting
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#weak-learnability" class="md-nav__link">
    Weak Learnability 的充分必要条件
  </a>
  
    <nav class="md-nav" aria-label="Weak Learnability 的充分必要条件">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    充分条件
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    必要条件
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/colorlessboy/Notes/edit/master/docs/ML/13-TheMarginsExplainationForBoosting.md" title="编辑此页" class="md-content__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
                  </a>
                
                
                  
                
                
                <h1 id="the-margins-explanation-for-boostings-effectiveness">The Margins Explanation for Boosting’s Effectiveness<a class="headerlink" href="#the-margins-explanation-for-boostings-effectiveness" title="Permanent link">&para;</a></h1>
<p>这是一篇阅读笔记，关于《Boosting Fundations and algorithms》的第五章。这一章解释了
Margin Theory 以及它在Boosting中的应用。</p>
<p>首先我们需要了解一下Margin Theory最原始的动机，《Understanding Machine Learning》
所涉及的理论误差界分析的是一个二分类问题（<span><span class="MathJax_Preview">y \in \{-1, 1\}</span><script type="math/tex">y \in \{-1, 1\}</script></span>）的如下的关系：</p>
<div>
<div class="MathJax_Preview">
    \mathbf{Pr}_{\mathcal{S} \sim \mathcal{D}}\{ \mathbb{E}_{(\mathbf{x}, y) 
    \sim \mathcal{D}}[\mathbf{1}_{h(\mathbf{x}) \ne y}] \le 
    \mathbb{E}_{(\mathbf{x}, y) \sim \mathcal{S}}[\mathbf{1}_{h(\mathbf{x}) \ne y}] 
    + \epsilon(m, \delta)\} \ge 1 - \delta,
</div>
<script type="math/tex; mode=display">
    \mathbf{Pr}_{\mathcal{S} \sim \mathcal{D}}\{ \mathbb{E}_{(\mathbf{x}, y) 
    \sim \mathcal{D}}[\mathbf{1}_{h(\mathbf{x}) \ne y}] \le 
    \mathbb{E}_{(\mathbf{x}, y) \sim \mathcal{S}}[\mathbf{1}_{h(\mathbf{x}) \ne y}] 
    + \epsilon(m, \delta)\} \ge 1 - \delta,
</script>
</div>
<p>其中 <span><span class="MathJax_Preview">\mathcal{S}</span><script type="math/tex">\mathcal{S}</script></span> 是从 <span><span class="MathJax_Preview">\mathcal{D}</span><script type="math/tex">\mathcal{D}</script></span> 中独立同分布采用了 <span><span class="MathJax_Preview">m</span><script type="math/tex">m</script></span> 个样本的样本集。上式要求
<span><span class="MathJax_Preview">h(\mathcal{x}) \in \{-1, 1\}</span><script type="math/tex">h(\mathcal{x}) \in \{-1, 1\}</script></span>, 如果 <span><span class="MathJax_Preview">h(\mathcal{x}) \in [-1, 1]</span><script type="math/tex">h(\mathcal{x}) \in [-1, 1]</script></span>，那么我们通常使用
<span><span class="MathJax_Preview">sign(h(\mathcal{x}))</span><script type="math/tex">sign(h(\mathcal{x}))</script></span> 来作为最终的二分类器。</p>
<p>但是，如果 <span><span class="MathJax_Preview">h(\mathcal{x}) \in [-1, 1]</span><script type="math/tex">h(\mathcal{x}) \in [-1, 1]</script></span> 那么上面的误差分析就不够精确，因为我们只关心 
<span><span class="MathJax_Preview">sign(h(\mathbf{x}))</span><script type="math/tex">sign(h(\mathbf{x}))</script></span> 是否等于 <span><span class="MathJax_Preview">y</span><script type="math/tex">y</script></span>，或者说 <span><span class="MathJax_Preview">yh(\mathbf{x})</span><script type="math/tex">yh(\mathbf{x})</script></span> 是否小于0。我们回过头再
看：如果 <span><span class="MathJax_Preview">h(\mathbf{x}) \in [-1, 1]</span><script type="math/tex">h(\mathbf{x}) \in [-1, 1]</script></span>，那么 <span><span class="MathJax_Preview">yh(\mathbf{x})</span><script type="math/tex">yh(\mathbf{x})</script></span> 本身也反映着分类器 <span><span class="MathJax_Preview">h</span><script type="math/tex">h</script></span> 
的某种置信程度：如果 <span><span class="MathJax_Preview">h(\mathbf{x})</span><script type="math/tex">h(\mathbf{x})</script></span> 远远大于0，那么 <span><span class="MathJax_Preview">h(\mathbf{x})</span><script type="math/tex">h(\mathbf{x})</script></span> 有很大的自信 
<span><span class="MathJax_Preview">y = 1</span><script type="math/tex">y = 1</script></span>。如果我没有理解错，那么 <span><span class="MathJax_Preview">y h(\mathcal{x})</span><script type="math/tex">y h(\mathcal{x})</script></span> 就是某种 <strong>margin</strong>，并且与 margin
有关的分析理论就叫做 <strong>margin theory</strong>。</p>
<p>我们今天用 margin theory 来研究一下 Boosting 的泛化误差，也就是 
<span><span class="MathJax_Preview">\mathbf{Pr}_{\mathcal{D}}(y h(\mathbf{x}) \le 0)</span><script type="math/tex">\mathbf{Pr}_{\mathcal{D}}(y h(\mathbf{x}) \le 0)</script></span> 的上界。
当然下面的文章符号会有些许变化，所以我先介绍一下。</p>
<p>对于 Boosting 算法，我们需要一个 Base Hypothesis Set <span><span class="MathJax_Preview">\mathcal{H}</span><script type="math/tex">\mathcal{H}</script></span>，而 Boosting 算法
会从 <span><span class="MathJax_Preview">\mathcal{H}</span><script type="math/tex">\mathcal{H}</script></span> 的凸包中选择一个分类器：</p>
<div>
<div class="MathJax_Preview">
Co(\mathcal{H}) = \left\{f(\mathbf{x}) = \sum^T_{t=1} \alpha_t h(\mathcal{x}) \vert  
\alpha_1, \ldots, \alpha_T \ge 0; \sum^T_{t=1} \alpha_t = 1; 
h_1, \ldots, h_T \in \mathcal{H}; T \ge 1\right\}.
</div>
<script type="math/tex; mode=display">
Co(\mathcal{H}) = \left\{f(\mathbf{x}) = \sum^T_{t=1} \alpha_t h(\mathcal{x}) \vert  
\alpha_1, \ldots, \alpha_T \ge 0; \sum^T_{t=1} \alpha_t = 1; 
h_1, \ldots, h_T \in \mathcal{H}; T \ge 1\right\}.
</script>
</div>
<h2 id="finite-base-hypothesis-space">Finite Base Hypothesis Space<a class="headerlink" href="#finite-base-hypothesis-space" title="Permanent link">&para;</a></h2>
<p>就像题目说的，我们首先来研究一下 <span><span class="MathJax_Preview">\mathcal{H}</span><script type="math/tex">\mathcal{H}</script></span> 是有限的情况下，我们能够得到什么。</p>
<div class="admonition 定理1">
<p class="admonition-title">定理1</p>
<p>样本空间 <span><span class="MathJax_Preview">\mathcal{X} \times \{-1, 1\}</span><script type="math/tex">\mathcal{X} \times \{-1, 1\}</script></span> 服从未知分布 <span><span class="MathJax_Preview">\mathcal{D}</span><script type="math/tex">\mathcal{D}</script></span>。样本集
<span><span class="MathJax_Preview">\mathcal{S}</span><script type="math/tex">\mathcal{S}</script></span> 包含 <span><span class="MathJax_Preview">m</span><script type="math/tex">m</script></span> 个样本空间采集的样本。如果 <span><span class="MathJax_Preview">\mathcal{H}</span><script type="math/tex">\mathcal{H}</script></span> 是有限的，
那么存在 <span><span class="MathJax_Preview">1 - \delta</span><script type="math/tex">1 - \delta</script></span> 的可能满足：对于任意的 <span><span class="MathJax_Preview">f \in Co(\mathcal{H})</span><script type="math/tex">f \in Co(\mathcal{H})</script></span>, </p>
<div>
<div class="MathJax_Preview">
   \mathbf{Pr}_{(\mathbf{x}, y) \sim \mathcal{D}} [y f(\mathbf{x}) \le 0]
    \le \mathbf{Pr}_{(\mathbf{x}, y) \sim \mathcal{S}} [y f(\mathbf{x}) \le 
    \theta] + O \left(\sqrt{\frac{\ln \vert \mathcal{H} \vert}{m \theta^{2}} 
    \ln\frac{m\theta^{2}}{\ln \vert \mathcal{H} \vert} 
    + \frac{\ln(1/\delta)}{m}}\right),
</div>
<script type="math/tex; mode=display">
   \mathbf{Pr}_{(\mathbf{x}, y) \sim \mathcal{D}} [y f(\mathbf{x}) \le 0]
    \le \mathbf{Pr}_{(\mathbf{x}, y) \sim \mathcal{S}} [y f(\mathbf{x}) \le 
    \theta] + O \left(\sqrt{\frac{\ln \vert \mathcal{H} \vert}{m \theta^{2}} 
    \ln\frac{m\theta^{2}}{\ln \vert \mathcal{H} \vert} 
    + \frac{\ln(1/\delta)}{m}}\right),
</script>
</div>
<p>其中要求 <span><span class="MathJax_Preview">\theta &gt; \sqrt{\ln \vert \mathcal{H} \vert / (4m)}</span><script type="math/tex">\theta > \sqrt{\ln \vert \mathcal{H} \vert / (4m)}</script></span>。</p>
</div>
<p>首先，这个界和 AdaBoost 的轮次 <span><span class="MathJax_Preview">T</span><script type="math/tex">T</script></span> 没有关系，所以高轮次的 AdaBoost 并不会引起
过拟合。</p>
<p>这个定理的证明思路还是非常巧妙的，我尝试整理一下吧。</p>
<p>证明过程中构造了一个经验分类器集合，它对应着 <span><span class="MathJax_Preview">Co(\mathcal{H})</span><script type="math/tex">Co(\mathcal{H})</script></span>：</p>
<div>
<div class="MathJax_Preview">
    \mathcal{A}_{n} = \left\{f(\mathbf{x}) = \frac{1}{n}\sum^{n}_{j=1}h_j(\mathbf{x})
        \vert h_1, \ldots, h_n \in \mathcal{H}\right\}.
</div>
<script type="math/tex; mode=display">
    \mathcal{A}_{n} = \left\{f(\mathbf{x}) = \frac{1}{n}\sum^{n}_{j=1}h_j(\mathbf{x})
        \vert h_1, \ldots, h_n \in \mathcal{H}\right\}.
</script>
</div>
<p>对于任意的 <span><span class="MathJax_Preview">f = \sum^{\vert \mathcal{H} \vert}_{i=1} \alpha_i h_i</span><script type="math/tex">f = \sum^{\vert \mathcal{H} \vert}_{i=1} \alpha_i h_i</script></span>, 我们依据权重
<span><span class="MathJax_Preview">\alpha_i</span><script type="math/tex">\alpha_i</script></span> 从 <span><span class="MathJax_Preview">\mathcal{H}</span><script type="math/tex">\mathcal{H}</script></span> 中独立同分布采集 <span><span class="MathJax_Preview">n</span><script type="math/tex">n</script></span> 个分类器，那么我们就可以获得一个
经验分类器 <span><span class="MathJax_Preview">\hat f = \frac{1}{n} \sum^{n}_{j = 1} h_j</span><script type="math/tex">\hat f = \frac{1}{n} \sum^{n}_{j = 1} h_j</script></span>，它是属于 <span><span class="MathJax_Preview">\mathcal{A}_n</span><script type="math/tex">\mathcal{A}_n</script></span>
的，我们定义经验分类器服从的测度空间为 <span><span class="MathJax_Preview">\mathcal{A}_n(f)</span><script type="math/tex">\mathcal{A}_n(f)</script></span>。</p>
<p>不规范的说，主体的证明思路是：</p>
<div>
<div class="MathJax_Preview">
    \mathbf{Pr}_{(\mathbf{x}, y) \sim \mathcal{D}}
        \left[y f(\mathbf{x}) \le 0\right] 
    \le \mathbf{Pr}_{(\mathbf{x}, y) \sim \mathcal{D}}
        \left[y \hat f(\mathbf{x}) \le \frac{\theta}{2}\right] \\
    \le \mathbf{Pr}_{(\mathbf{x}, y) \sim \mathcal{S}}
        \left[y \hat f(\mathbf{x}) \le \frac{\theta}{2}\right]
    \le \mathbf{Pr}_{(\mathbf{x}, y) \sim \mathcal{S}}
        \left[y f(\mathbf{x}) \le \theta\right].
</div>
<script type="math/tex; mode=display">
    \mathbf{Pr}_{(\mathbf{x}, y) \sim \mathcal{D}}
        \left[y f(\mathbf{x}) \le 0\right] 
    \le \mathbf{Pr}_{(\mathbf{x}, y) \sim \mathcal{D}}
        \left[y \hat f(\mathbf{x}) \le \frac{\theta}{2}\right] \\
    \le \mathbf{Pr}_{(\mathbf{x}, y) \sim \mathcal{S}}
        \left[y \hat f(\mathbf{x}) \le \frac{\theta}{2}\right]
    \le \mathbf{Pr}_{(\mathbf{x}, y) \sim \mathcal{S}}
        \left[y f(\mathbf{x}) \le \theta\right].
</script>
</div>
<p>其中 <span><span class="MathJax_Preview">\hat f</span><script type="math/tex">\hat f</script></span> 起到了很重要的桥梁的作用。</p>
<div class="admonition 引理1">
<p class="admonition-title">引理1</p>
<p>根据霍夫听不等式，我们可得：对于任意的 <span><span class="MathJax_Preview">x, f</span><script type="math/tex">x, f</script></span>, 以及 <span><span class="MathJax_Preview">n \ge 1, \theta &gt; 0</span><script type="math/tex">n \ge 1, \theta > 0</script></span>，满足</p>
<div>
<div class="MathJax_Preview">
    \mathbf{Pr}_{\hat f \sim \mathcal{A}_n(f)}
    \left[
        \vert \hat f(x) - f(x) \vert \ge \frac{\theta}{2}
    \right] \le 2 e ^{-n\theta^2/8} = \beta_{n, \theta}.
</div>
<script type="math/tex; mode=display">
    \mathbf{Pr}_{\hat f \sim \mathcal{A}_n(f)}
    \left[
        \vert \hat f(x) - f(x) \vert \ge \frac{\theta}{2}
    \right] \le 2 e ^{-n\theta^2/8} = \beta_{n, \theta}.
</script>
</div>
</div>
<p>自然我们可得一条新的引理</p>
<div class="admonition 引理2">
<p class="admonition-title">引理2</p>
<p>对于任意的 <span><span class="MathJax_Preview">(x, y) \sim \mathcal{D}, f</span><script type="math/tex">(x, y) \sim \mathcal{D}, f</script></span>，以及 <span><span class="MathJax_Preview">n \ge 1, \theta &gt; 0</span><script type="math/tex">n \ge 1, \theta > 0</script></span>，满足</p>
<div>
<div class="MathJax_Preview">
    \mathbf{Pr}_{(x,y)\sim \mathcal{D}, \hat f \sim \mathcal{A}_n(f)}
    \left[\vert y f(x) - y \hat f(x) \vert \ge \frac{\theta}{2} \right]
    \le \beta_{n, \theta}.
</div>
<script type="math/tex; mode=display">
    \mathbf{Pr}_{(x,y)\sim \mathcal{D}, \hat f \sim \mathcal{A}_n(f)}
    \left[\vert y f(x) - y \hat f(x) \vert \ge \frac{\theta}{2} \right]
    \le \beta_{n, \theta}.
</script>
</div>
</div>
<p>这条引理也非常简单，因为 <span><span class="MathJax_Preview">y \in \{-1, 1\}</span><script type="math/tex">y \in \{-1, 1\}</script></span>，以及绝对值符合保证它可以被忽略，接下来就是
使用引理1即可。</p>
<p>那么我们先做第一步放缩：</p>
<div>
<div class="MathJax_Preview">
\begin{aligned}
    &amp;\mathbf{Pr}_{(x, y) \sim \mathcal{D}}[y f(x) \le 0] \\
    =&amp; \mathbf{Pr}_{(x, y) \sim \mathcal{D}, \hat f \sim \mathcal{A}_n(f)}[y f(x) \le 0]\\
    \le&amp; \mathbf{Pr}_{(x, y) \sim \mathcal{D}, \hat f \sim \mathcal{A}_n(f)}
        \left[y \hat f(x) \le \frac{\theta}{2}\right] \\
    &amp; + \mathbf{Pr}_{(x, y) \sim \mathcal{D}, \hat f \sim \mathcal{A}_n(f)}
        \left[
            y f(x) \le 0, y \hat f(x) &gt; \frac{\theta}{2}
        \right]\\
    \le&amp; \mathbf{Pr}_{(x, y) \sim \mathcal{D}, \hat f \sim \mathcal{A}_n(f)}
        \left[y \hat f(x) \le \frac{\theta}{2}\right] \\
    &amp; + \mathbf{Pr}_{(x, y) \sim \mathcal{D}, \hat f \sim \mathcal{A}_n(f)}
        \left[
            \vert y f(x) - y \hat f(x) \vert &gt; \frac{\theta}{2}
        \right]\\
    \le&amp; \mathbf{Pr}_{(x, y) \sim \mathcal{D}, \hat f \sim \mathcal{A}_n(f)}
        \left[y \hat f(x) \le \frac{\theta}{2}\right] + \beta_{n, \theta}.
\end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned}
    &\mathbf{Pr}_{(x, y) \sim \mathcal{D}}[y f(x) \le 0] \\
    =& \mathbf{Pr}_{(x, y) \sim \mathcal{D}, \hat f \sim \mathcal{A}_n(f)}[y f(x) \le 0]\\
    \le& \mathbf{Pr}_{(x, y) \sim \mathcal{D}, \hat f \sim \mathcal{A}_n(f)}
        \left[y \hat f(x) \le \frac{\theta}{2}\right] \\
    & + \mathbf{Pr}_{(x, y) \sim \mathcal{D}, \hat f \sim \mathcal{A}_n(f)}
        \left[
            y f(x) \le 0, y \hat f(x) > \frac{\theta}{2}
        \right]\\
    \le& \mathbf{Pr}_{(x, y) \sim \mathcal{D}, \hat f \sim \mathcal{A}_n(f)}
        \left[y \hat f(x) \le \frac{\theta}{2}\right] \\
    & + \mathbf{Pr}_{(x, y) \sim \mathcal{D}, \hat f \sim \mathcal{A}_n(f)}
        \left[
            \vert y f(x) - y \hat f(x) \vert > \frac{\theta}{2}
        \right]\\
    \le& \mathbf{Pr}_{(x, y) \sim \mathcal{D}, \hat f \sim \mathcal{A}_n(f)}
        \left[y \hat f(x) \le \frac{\theta}{2}\right] + \beta_{n, \theta}.
\end{aligned}
</script>
</div>
<p>类似的，我们可以获得</p>
<div>
<div class="MathJax_Preview">
\begin{aligned}
    &amp;\mathbf{Pr}_{(x, y) \sim \mathcal{S}, \hat f \sim \mathcal{A}_n(f)}
    \left[ y \hat f(x) \le \frac{\theta}{2} \right]\\
    \le&amp; \mathbf{Pr}_{(x, y) \sim \mathcal{S}, \hat f \sim \mathcal{A}_n(f)}
        \left[ y f(x) \le \theta \right]\\
    &amp;+ \mathbf{Pr}_{(x, y) \sim \mathcal{S}, \hat f \sim \mathcal{A}_n(f)}
        \left[
            y \hat f(x) \le \frac{\theta}{2}, y f(x) \ge \theta
        \right] \\
    \le&amp; \mathbf{Pr}_{(x, y) \sim \mathcal{S}, \hat f \sim \mathcal{A}_n(f)}
        \left[ y f(x) \le \theta \right]\\
    &amp;+ \mathbf{Pr}_{(x, y) \sim \mathcal{S}, \hat f \sim \mathcal{A}_n(f)}
        \left[
            \vert y \hat f(x) - y f(x) \vert \ge \frac{\theta}{2}
        \right] \\
    \le&amp; \mathbf{Pr}_{(x, y) \sim \mathcal{S}}[y f(x) \le \theta] + \beta_{n, \theta}.
\end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned}
    &\mathbf{Pr}_{(x, y) \sim \mathcal{S}, \hat f \sim \mathcal{A}_n(f)}
    \left[ y \hat f(x) \le \frac{\theta}{2} \right]\\
    \le& \mathbf{Pr}_{(x, y) \sim \mathcal{S}, \hat f \sim \mathcal{A}_n(f)}
        \left[ y f(x) \le \theta \right]\\
    &+ \mathbf{Pr}_{(x, y) \sim \mathcal{S}, \hat f \sim \mathcal{A}_n(f)}
        \left[
            y \hat f(x) \le \frac{\theta}{2}, y f(x) \ge \theta
        \right] \\
    \le& \mathbf{Pr}_{(x, y) \sim \mathcal{S}, \hat f \sim \mathcal{A}_n(f)}
        \left[ y f(x) \le \theta \right]\\
    &+ \mathbf{Pr}_{(x, y) \sim \mathcal{S}, \hat f \sim \mathcal{A}_n(f)}
        \left[
            \vert y \hat f(x) - y f(x) \vert \ge \frac{\theta}{2}
        \right] \\
    \le& \mathbf{Pr}_{(x, y) \sim \mathcal{S}}[y f(x) \le \theta] + \beta_{n, \theta}.
\end{aligned}
</script>
</div>
<p>我们最后还差一条引理，来连接上面两个结论：</p>
<div class="admonition 引理3">
<p class="admonition-title">引理3</p>
<p>定义 <span><span class="MathJax_Preview">\epsilon_n = \sqrt{\ln[n(n+1)^2 \vert \mathcal{H} \vert^n / \delta]/2m}</span><script type="math/tex">\epsilon_n = \sqrt{\ln[n(n+1)^2 \vert \mathcal{H} \vert^n / \delta]/2m}</script></span>,
其中 <span><span class="MathJax_Preview">m</span><script type="math/tex">m</script></span> 是 <span><span class="MathJax_Preview">\mathcal{S}</span><script type="math/tex">\mathcal{S}</script></span> 的大小。那么，我们有</p>
<div>
<div class="MathJax_Preview">
    \mathbf{Pr}_{\mathcal{S} \sim \mathcal{D}} \left \{
        \forall n \ge 1, \hat f \in \mathcal{A}_n, \theta&gt;0:
        \mathbf{Pr}_{(x, y) \sim \mathcal{D}}
        \left[
            y \hat f(x) \le \frac{\theta}{2}
        \right]
        \le \mathbf{Pr}_{(x, y) \sim \mathcal{S}}
        \left[
            y \hat f(x) \le \frac{\theta}{2}    
        \right] + \epsilon_n
    \right\} \ge 1 - \delta.
</div>
<script type="math/tex; mode=display">
    \mathbf{Pr}_{\mathcal{S} \sim \mathcal{D}} \left \{
        \forall n \ge 1, \hat f \in \mathcal{A}_n, \theta>0:
        \mathbf{Pr}_{(x, y) \sim \mathcal{D}}
        \left[
            y \hat f(x) \le \frac{\theta}{2}
        \right]
        \le \mathbf{Pr}_{(x, y) \sim \mathcal{S}}
        \left[
            y \hat f(x) \le \frac{\theta}{2}    
        \right] + \epsilon_n
    \right\} \ge 1 - \delta.
</script>
</div>
</div>
<details class="证明"><summary>证明</summary><p>设 </p>
<div>
<div class="MathJax_Preview">
    p_{\hat f, \theta} = 
    \mathbf{Pr}_{(x, y) \sim \mathcal{D}}
    \left[
        y \hat f(x) \le \frac{\theta}{2}
    \right],
</div>
<script type="math/tex; mode=display">
    p_{\hat f, \theta} = 
    \mathbf{Pr}_{(x, y) \sim \mathcal{D}}
    \left[
        y \hat f(x) \le \frac{\theta}{2}
    \right],
</script>
</div>
<p>以及</p>
<div>
<div class="MathJax_Preview">
    \hat p_{\hat f, \theta} = 
    \mathbf{Pr}_{(x, y) \sim \mathcal{S}}
    \left[
        y \hat f(x) \le \frac{\theta}{2}
    \right].
</div>
<script type="math/tex; mode=display">
    \hat p_{\hat f, \theta} = 
    \mathbf{Pr}_{(x, y) \sim \mathcal{S}}
    \left[
        y \hat f(x) \le \frac{\theta}{2}
    \right].
</script>
</div>
<p>很明显 <span><span class="MathJax_Preview">\mathbb{E}_{\mathcal{S} \sim \mathcal{D}}[\hat p_{\hat f,\theta}] = p_{\hat f, \theta}</span><script type="math/tex">\mathbb{E}_{\mathcal{S} \sim \mathcal{D}}[\hat p_{\hat f,\theta}] = p_{\hat f, \theta}</script></span>,
因此我们可以使用霍夫听不等式得到：</p>
<div>
<div class="MathJax_Preview">
    \mathbf{Pr}_{\mathcal{S} \sim \mathcal{D}}
    \left[
        p_{\hat f, \theta} \ge \hat p_{\hat f, \theta} + \epsilon_n
    \right] \le e^{-2\epsilon^2_n m}.
</div>
<script type="math/tex; mode=display">
    \mathbf{Pr}_{\mathcal{S} \sim \mathcal{D}}
    \left[
        p_{\hat f, \theta} \ge \hat p_{\hat f, \theta} + \epsilon_n
    \right] \le e^{-2\epsilon^2_n m}.
</script>
</div>
<p>接下来的事情就比较巧妙了。
我们注意到 <span><span class="MathJax_Preview">\hat f(x) = \frac{1}{n}\sum^n_{j=1}\hat h_j(x)</span><script type="math/tex">\hat f(x) = \frac{1}{n}\sum^n_{j=1}\hat h_j(x)</script></span>，所以如果
<span><span class="MathJax_Preview">y \hat f(x) \le \frac{\theta}{2}</span><script type="math/tex">y \hat f(x) \le \frac{\theta}{2}</script></span> 当且仅当 
<span><span class="MathJax_Preview">y\sum^n_{j=1}\hat h_j(x) \le \frac{n \theta}{2}</span><script type="math/tex">y\sum^n_{j=1}\hat h_j(x) \le \frac{n \theta}{2}</script></span>。
又因为 <span><span class="MathJax_Preview">h_j(x) \in \{-1, 1\}</span><script type="math/tex">h_j(x) \in \{-1, 1\}</script></span>，所以还等价于
<span><span class="MathJax_Preview">y\sum^n_{j=1}\hat h_j(x) \le \lfloor{n \theta}/{2}\rfloor</span><script type="math/tex">y\sum^n_{j=1}\hat h_j(x) \le \lfloor{n \theta}/{2}\rfloor</script></span>。</p>
<p>又因为 <span><span class="MathJax_Preview">\theta &gt; 2</span><script type="math/tex">\theta > 2</script></span> 没必要考虑，所以启发我们定义一个集合</p>
<div>
<div class="MathJax_Preview">
    \Theta_n = \left\{
        \frac{2i}{n}: i = 0, 1, \ldots, n
    \right\}.
</div>
<script type="math/tex; mode=display">
    \Theta_n = \left\{
        \frac{2i}{n}: i = 0, 1, \ldots, n
    \right\}.
</script>
</div>
<p>那么我们有</p>
<div>
<div class="MathJax_Preview">
\begin{aligned}
    &amp;\mathbf{Pr}
        \left[
            \exists \hat f \in \mathcal{A}_n, \theta \ge 0: 
            p_{\hat f, \theta} \ge \hat p_{\hat f, \theta} + \epsilon_n
        \right] \\
    =&amp;\mathbf{Pr}
        \left[
            \exists \hat f \in \mathcal{A}_n, \theta \in \Theta_n: 
            p_{\hat f, \theta} \ge \hat p_{\hat f, \theta} + \epsilon_n
        \right] \\
    =&amp; \vert \mathcal{A}_n \vert \cdot \vert \Theta_n \vert \cdot e ^{-2\epsilon^2_n m}\\
    \le&amp; \vert \mathcal{H} \vert^n \cdot (n + 1) \cdot e ^{-2\epsilon^2_n m}\\
    =&amp; \frac{\delta}{n(n+1)}.
\end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned}
    &\mathbf{Pr}
        \left[
            \exists \hat f \in \mathcal{A}_n, \theta \ge 0: 
            p_{\hat f, \theta} \ge \hat p_{\hat f, \theta} + \epsilon_n
        \right] \\
    =&\mathbf{Pr}
        \left[
            \exists \hat f \in \mathcal{A}_n, \theta \in \Theta_n: 
            p_{\hat f, \theta} \ge \hat p_{\hat f, \theta} + \epsilon_n
        \right] \\
    =& \vert \mathcal{A}_n \vert \cdot \vert \Theta_n \vert \cdot e ^{-2\epsilon^2_n m}\\
    \le& \vert \mathcal{H} \vert^n \cdot (n + 1) \cdot e ^{-2\epsilon^2_n m}\\
    =& \frac{\delta}{n(n+1)}.
\end{aligned}
</script>
</div>
<p>又因为 <span><span class="MathJax_Preview">\sum^{\infty}_{n=1} \frac{\delta}{n(n+1)} = \delta</span><script type="math/tex">\sum^{\infty}_{n=1} \frac{\delta}{n(n+1)} = \delta</script></span>，我们最终证明了定理3。</p>
</details>
<p>最终，我们证明了定理1：</p>
<div>
<div class="MathJax_Preview">  
\begin{aligned}
    &amp;\mathbf{Pr}_{(x, y) \sim \mathcal{D}}[y f(x) \le 0]\\
    \le&amp; \mathbf{Pr}_{(x, y) \sim \mathcal{D}, \hat f\sim \mathcal{A}_n(f)}
        \left[
            y \hat f(x) \le \frac{\theta}{2}
        \right] + \beta_{n, \theta}\\
    \le&amp; \mathbf{Pr}_{(x, y) \sim \mathcal{S}, \hat f\sim \mathcal{A}_n(f)}
        \left[
            y \hat f(x) \le \frac{\theta}{2}
        \right] + \epsilon_n + \beta_{n, \theta}\\
    \le&amp; \mathbf{Pr}_{(x, y) \sim \mathcal{S}}
        \left[
            y f(x) \le \theta
        \right] + \epsilon_n + 2\beta_{n, \theta}\\
    \le&amp; \mathbf{Pr}_{(x, y) \sim \mathcal{S}}
        \left[
            y f(x) \le \theta
        \right] + 4e^{-n\theta^2/8} \\
    &amp; + \sqrt{\ln[n(n+1)^2 \vert \mathcal{H} \vert^n / \delta]/2m}.
\end{aligned}
</div>
<script type="math/tex; mode=display">  
\begin{aligned}
    &\mathbf{Pr}_{(x, y) \sim \mathcal{D}}[y f(x) \le 0]\\
    \le& \mathbf{Pr}_{(x, y) \sim \mathcal{D}, \hat f\sim \mathcal{A}_n(f)}
        \left[
            y \hat f(x) \le \frac{\theta}{2}
        \right] + \beta_{n, \theta}\\
    \le& \mathbf{Pr}_{(x, y) \sim \mathcal{S}, \hat f\sim \mathcal{A}_n(f)}
        \left[
            y \hat f(x) \le \frac{\theta}{2}
        \right] + \epsilon_n + \beta_{n, \theta}\\
    \le& \mathbf{Pr}_{(x, y) \sim \mathcal{S}}
        \left[
            y f(x) \le \theta
        \right] + \epsilon_n + 2\beta_{n, \theta}\\
    \le& \mathbf{Pr}_{(x, y) \sim \mathcal{S}}
        \left[
            y f(x) \le \theta
        \right] + 4e^{-n\theta^2/8} \\
    & + \sqrt{\ln[n(n+1)^2 \vert \mathcal{H} \vert^n / \delta]/2m}.
\end{aligned}
</script>
</div>
<p>当设定 </p>
<div>
<div class="MathJax_Preview">
    n = 
    \left\lceil 
        \frac{4}{\theta^2} \ln \left(\frac{4m\theta^2}{\ln\vert\mathcal{H}\vert}\right) 
    \right\rceil,
</div>
<script type="math/tex; mode=display">
    n = 
    \left\lceil 
        \frac{4}{\theta^2} \ln \left(\frac{4m\theta^2}{\ln\vert\mathcal{H}\vert}\right) 
    \right\rceil,
</script>
</div>
<p>我们就得到了定理1，应该还是需要一些不等式放缩的步骤，这里书上省略了，我也不追究了。
总的来说，这个界对 <span><span class="MathJax_Preview">n</span><script type="math/tex">n</script></span> 的大小有限制，<span><span class="MathJax_Preview">m</span><script type="math/tex">m</script></span> 越大， <span><span class="MathJax_Preview">n</span><script type="math/tex">n</script></span> 可以越大。这个界还是很奇怪的，
我觉得目前的表达方式并没有体现出它的本质：对任意的 <span><span class="MathJax_Preview">f</span><script type="math/tex">f</script></span> 都有这个界，这个界也太松弛了吧。</p>
<h2 id="infinite-base-hypothesis-spaces">Infinite Base Hypothesis Spaces<a class="headerlink" href="#infinite-base-hypothesis-spaces" title="Permanent link">&para;</a></h2>
<p>我们使用假设集的 VC-维 来做类似的采样复杂度的界，下面的定理非常类似定理1。</p>
<div class="admonition 定理2">
<p class="admonition-title">定理2</p>
<p>样本空间 <span><span class="MathJax_Preview">\mathcal{X} \times \{-1, 1\}</span><script type="math/tex">\mathcal{X} \times \{-1, 1\}</script></span> 服从未知分布 <span><span class="MathJax_Preview">\mathcal{D}</span><script type="math/tex">\mathcal{D}</script></span>。样本集
<span><span class="MathJax_Preview">\mathcal{S}</span><script type="math/tex">\mathcal{S}</script></span> 包含 <span><span class="MathJax_Preview">m</span><script type="math/tex">m</script></span> 个样本空间采集的样本。如果 <span><span class="MathJax_Preview">\mathcal{H}</span><script type="math/tex">\mathcal{H}</script></span> 的 VC-维 是 <span><span class="MathJax_Preview">d</span><script type="math/tex">d</script></span>。
对于 <span><span class="MathJax_Preview">m \ge d \ge 1</span><script type="math/tex">m \ge d \ge 1</script></span> 以及 <span><span class="MathJax_Preview">\delta &gt; 0</span><script type="math/tex">\delta > 0</script></span>，那么对于任意的 <span><span class="MathJax_Preview">f \in Co(\mathcal{H})</span><script type="math/tex">f \in Co(\mathcal{H})</script></span>, </p>
<div>
<div class="MathJax_Preview">
    \mathbf{Pr}_{\mathcal{S} \sim \mathcal{D}} \left\{
        \forall \theta &gt; \sqrt{8d \ln(em / d) / m}:
    \mathbf{Pr}_{(x, y) \sim \mathcal{D}} [ y f(x) \le 0]
    \le \mathbf{Pr}_{(x, y) \sim \mathcal{S}}[y f(x) \le \theta] + 
    O \left( \sqrt{
        \frac{d \ln(m / d) \ln(m \theta^2 / d)}{m\theta^2}
        + \frac{\ln(1 / \delta)}{m}
    }\right)
    \right\} &gt; 1 - \delta.
</div>
<script type="math/tex; mode=display">
    \mathbf{Pr}_{\mathcal{S} \sim \mathcal{D}} \left\{
        \forall \theta > \sqrt{8d \ln(em / d) / m}:
    \mathbf{Pr}_{(x, y) \sim \mathcal{D}} [ y f(x) \le 0]
    \le \mathbf{Pr}_{(x, y) \sim \mathcal{S}}[y f(x) \le \theta] + 
    O \left( \sqrt{
        \frac{d \ln(m / d) \ln(m \theta^2 / d)}{m\theta^2}
        + \frac{\ln(1 / \delta)}{m}
    }\right)
    \right\} > 1 - \delta.
</script>
</div>
</div>
<p>相比于定理1，定理2的证明需要解决的关键问题是如何修改引理3。</p>
<div class="admonition 引理4">
<p class="admonition-title">引理4</p>
<p>定义</p>
<div>
<div class="MathJax_Preview">
    \epsilon_n = \sqrt{\frac{32}{m} [\ln(n(n+1)^2) + dn \ln(em / d) + \ln(8/\delta)]}.
</div>
<script type="math/tex; mode=display">
    \epsilon_n = \sqrt{\frac{32}{m} [\ln(n(n+1)^2) + dn \ln(em / d) + \ln(8/\delta)]}.
</script>
</div>
<p>我们有：</p>
<div>
<div class="MathJax_Preview">
    \mathbf{Pr}_{\mathcal{S}\sim \mathcal{D}} \left\{
        \forall n \ge 1, \hat f \in \mathcal{A}_n, \theta \ge 0:
        \mathbf{Pr}_{(x, y) \sim \mathcal{D}}
        \left[y \hat f(x) \le \frac{\theta}{2}\right] 
        \le
        \mathbf{Pr}_{(x, y) \sim \mathcal{S}}
        \left[y \hat f(x) \le \frac{\theta}{2}\right] + \epsilon_n
    \right\} \ge 1 - \delta.
</div>
<script type="math/tex; mode=display">
    \mathbf{Pr}_{\mathcal{S}\sim \mathcal{D}} \left\{
        \forall n \ge 1, \hat f \in \mathcal{A}_n, \theta \ge 0:
        \mathbf{Pr}_{(x, y) \sim \mathcal{D}}
        \left[y \hat f(x) \le \frac{\theta}{2}\right] 
        \le
        \mathbf{Pr}_{(x, y) \sim \mathcal{S}}
        \left[y \hat f(x) \le \frac{\theta}{2}\right] + \epsilon_n
    \right\} \ge 1 - \delta.
</script>
</div>
</div>
<details class="证明"><summary>证明</summary><p>对于样本空间 <span><span class="MathJax_Preview">\mathcal{Z} = \mathcal{X} \times \{-1, +1\}</span><script type="math/tex">\mathcal{Z} = \mathcal{X} \times \{-1, +1\}</script></span>，我们构造它的一个子集</p>
<div>
<div class="MathJax_Preview">
    B_{\hat f, \theta} = \left\{
        (x, y) \in \mathcal{Z}: y \hat f(x) \le \theta/2    
    \right\}
</div>
<script type="math/tex; mode=display">
    B_{\hat f, \theta} = \left\{
        (x, y) \in \mathcal{Z}: y \hat f(x) \le \theta/2    
    \right\}
</script>
</div>
<p>来表示样本点满足对应 <span><span class="MathJax_Preview">\hat f(x)</span><script type="math/tex">\hat f(x)</script></span> 的 margin 最多为 <span><span class="MathJax_Preview">\theta/2</span><script type="math/tex">\theta/2</script></span> 的点的集合。
我们再定义 <span><span class="MathJax_Preview">B_{\hat f, \theta}</span><script type="math/tex">B_{\hat f, \theta}</script></span> 的集合：</p>
<div>
<div class="MathJax_Preview">
    \mathcal{B}_n = \left\{
        B_{\hat f, \theta}: \hat f \in \mathcal{A}_n, \theta \ge 0    
    \right\}.
</div>
<script type="math/tex; mode=display">
    \mathcal{B}_n = \left\{
        B_{\hat f, \theta}: \hat f \in \mathcal{A}_n, \theta \ge 0    
    \right\}.
</script>
</div>
<p>接下来我们希望求解一下 <span><span class="MathJax_Preview">\mathcal{B}_n</span><script type="math/tex">\mathcal{B}_n</script></span> 的增长函数 <span><span class="MathJax_Preview">\Pi_{\mathcal{B}_n}(m)</span><script type="math/tex">\Pi_{\mathcal{B}_n}(m)</script></span>
（再我的笔记里，也叫它 <span><span class="MathJax_Preview">\tau_{\mathcal{B}_n}(m)</span><script type="math/tex">\tau_{\mathcal{B}_n}(m)</script></span>）。
因为假设 <span><span class="MathJax_Preview">\mathcal{H}</span><script type="math/tex">\mathcal{H}</script></span> 的 VC维 是 <span><span class="MathJax_Preview">d</span><script type="math/tex">d</script></span>，所以根据 Sauer's 引理，当 <span><span class="MathJax_Preview">m \ge d \ge 1</span><script type="math/tex">m \ge d \ge 1</script></span>时，
我们可得：</p>
<div>
<div class="MathJax_Preview">
    \vert \left\{
        \langle 
            h(x_1), \ldots, h(x_m)
        \rangle: h \in \mathcal{H}
    \right\} \vert \le (em / d)^d.
</div>
<script type="math/tex; mode=display">
    \vert \left\{
        \langle 
            h(x_1), \ldots, h(x_m)
        \rangle: h \in \mathcal{H}
    \right\} \vert \le (em / d)^d.
</script>
</div>
<p>我们可以很快地得到一个非常松弛的界</p>
<div>
<div class="MathJax_Preview">
    \vert \left\{
        \langle 
            y_1 \hat f(x_1), \ldots, y_m \hat f(x_m)
        \rangle: \hat f \in \mathcal{A}_n
    \right\} \vert \le (em / d)^{dn}.
</div>
<script type="math/tex; mode=display">
    \vert \left\{
        \langle 
            y_1 \hat f(x_1), \ldots, y_m \hat f(x_m)
        \rangle: \hat f \in \mathcal{A}_n
    \right\} \vert \le (em / d)^{dn}.
</script>
</div>
<p>这里因为 <span><span class="MathJax_Preview">n</span><script type="math/tex">n</script></span> 是确定的，所以 <span><span class="MathJax_Preview">\hat f(x)</span><script type="math/tex">\hat f(x)</script></span> 也是离散的点，所以我们可以使用类似引理3的
技术，构造集合 <span><span class="MathJax_Preview">\Theta_n</span><script type="math/tex">\Theta_n</script></span>, 得到：</p>
<div>
<div class="MathJax_Preview">
    \Pi_{\mathcal{B}_n}(m) \le (n+1) (em/d)^{dn}.
</div>
<script type="math/tex; mode=display">
    \Pi_{\mathcal{B}_n}(m) \le (n+1) (em/d)^{dn}.
</script>
</div>
<p>VC维有一个定理（原书定理2.6）：如果 <span><span class="MathJax_Preview">\mathcal{A}</span><script type="math/tex">\mathcal{A}</script></span> 是集合 <span><span class="MathJax_Preview">Z</span><script type="math/tex">Z</script></span> 子集的集合，那么有：</p>
<div>
<div class="MathJax_Preview">
    \mathbf{Pr}_{\mathcal{S} \sim \mathcal{D}}
    \left\{
        \exists A \in \mathcal{A}: 
        \mathbf{Pr}_{z \sim \mathcal{D}}[z \in A] 
        \ge \mathbf{Pr}_{z \sim \mathcal{S}}[z \in A]
        + \epsilon
    \right\} \le 8 \Pi_{\mathcal{A}}(m) e^{-m \epsilon^2 / 32}.
</div>
<script type="math/tex; mode=display">
    \mathbf{Pr}_{\mathcal{S} \sim \mathcal{D}}
    \left\{
        \exists A \in \mathcal{A}: 
        \mathbf{Pr}_{z \sim \mathcal{D}}[z \in A] 
        \ge \mathbf{Pr}_{z \sim \mathcal{S}}[z \in A]
        + \epsilon
    \right\} \le 8 \Pi_{\mathcal{A}}(m) e^{-m \epsilon^2 / 32}.
</script>
</div>
<p>带入可得：</p>
<div>
<div class="MathJax_Preview">
    \mathbf{Pr}_{\mathcal{S} \sim \mathcal{D}}
    \left\{
        \forall B_{\hat f, \theta} \in \mathcal{B}_n,
        \mathbf{Pr}_{z \sim \mathcal{D}}[z \in B_{\hat f, \theta}]
        \le
        \mathbf{Pr}_{z \sim \mathcal{S}}[z \in B_{\hat f, \theta}]
        + \epsilon_n
    \right\} \ge 1 - \delta/(n(n+1)).
</div>
<script type="math/tex; mode=display">
    \mathbf{Pr}_{\mathcal{S} \sim \mathcal{D}}
    \left\{
        \forall B_{\hat f, \theta} \in \mathcal{B}_n,
        \mathbf{Pr}_{z \sim \mathcal{D}}[z \in B_{\hat f, \theta}]
        \le
        \mathbf{Pr}_{z \sim \mathcal{S}}[z \in B_{\hat f, \theta}]
        + \epsilon_n
    \right\} \ge 1 - \delta/(n(n+1)).
</script>
</div>
<p>那么，我们再聚集一下 <span><span class="MathJax_Preview">\mathbf{B}_n</span><script type="math/tex">\mathbf{B}_n</script></span>，对于任意的 <span><span class="MathJax_Preview">n \ge 1</span><script type="math/tex">n \ge 1</script></span>，我们都有至少 <span><span class="MathJax_Preview">1 - \delta</span><script type="math/tex">1 - \delta</script></span> 
的概率得到引理4。</p>
</details>
<p>我们综合上述结论，类似于有限假设集，我们可以得到定理2，不过要设置：</p>
<div>
<div class="MathJax_Preview">
    n = \left\lceil
        \frac{4}{\theta^2} \ln \left(
            \frac{m \theta^2}{8d \ln(em / d)}
        \right)
    \right\rceil.
</div>
<script type="math/tex; mode=display">
    n = \left\lceil
        \frac{4}{\theta^2} \ln \left(
            \frac{m \theta^2}{8d \ln(em / d)}
        \right)
    \right\rceil.
</script>
</div>
<p>综上所述，<span><span class="MathJax_Preview">\tilde O(1 / \sqrt{m})</span><script type="math/tex">\tilde O(1 / \sqrt{m})</script></span> 是一个非常松弛的界，如果我们有 consistent 假设，
也就是所有经验误差值可以降到0，那么我们能够获得一个更好的界 <span><span class="MathJax_Preview">\tilde O(1 / m)</span><script type="math/tex">\tilde O(1 / m)</script></span>。</p>
<h2 id="rademacher">基于 Rademacher 复杂度的分析<a class="headerlink" href="#rademacher" title="Permanent link">&para;</a></h2>
<p>一些 Rademacher 的前置知识可以翻阅前面的笔记。接下来用到了一系列 Rademacher 复杂度的
数学性质。</p>
<p>我们先引入一个函数集合</p>
<div>
<div class="MathJax_Preview">
    \mathcal{M} = \left\{
        (x, y) \mapsto y f(x) \vert f \in co(\mathcal{H})
    \right\}.
</div>
<script type="math/tex; mode=display">
    \mathcal{M} = \left\{
        (x, y) \mapsto y f(x) \vert f \in co(\mathcal{H})
    \right\}.
</script>
</div>
<p>受限我们可得： <span><span class="MathJax_Preview">R_S(\mathcal{M}) = R_S(co(\mathcal{H})) = R_S(\mathcal{H})</span><script type="math/tex">R_S(\mathcal{M}) = R_S(co(\mathcal{H})) = R_S(\mathcal{H})</script></span>。</p>
<p>我们引入一个分段线性函数（<span><span class="MathJax_Preview">0-1</span><script type="math/tex">0-1</script></span>损失函数的变形）：</p>
<div>
<div class="MathJax_Preview">
\phi(u) = 
\begin{cases}
    1 &amp; u \le 0,\\
    1 - u/\theta &amp; 0\le u \le \theta,\\
    0 &amp; u \ge \theta.
\end{cases}
</div>
<script type="math/tex; mode=display">
\phi(u) = 
\begin{cases}
    1 & u \le 0,\\
    1 - u/\theta & 0\le u \le \theta,\\
    0 & u \ge \theta.
\end{cases}
</script>
</div>
<p>因为 <span><span class="MathJax_Preview">\phi(u)</span><script type="math/tex">\phi(u)</script></span> 是 <span><span class="MathJax_Preview">1/\theta</span><script type="math/tex">1/\theta</script></span>-Lipschitz 连续函数，如果假设集 <span><span class="MathJax_Preview">\mathcal{H}</span><script type="math/tex">\mathcal{H}</script></span> 的 VC-维
是 <span><span class="MathJax_Preview">d</span><script type="math/tex">d</script></span>, 我们就能得到：</p>
<div>
<div class="MathJax_Preview">
    R_S(\phi \circ \mathcal{M}) \le \frac{1}{\theta} R_S(\mathcal{M})
    \le \frac{1}{\theta} \sqrt{\frac{2d}{m} \ln(em/d)}.
</div>
<script type="math/tex; mode=display">
    R_S(\phi \circ \mathcal{M}) \le \frac{1}{\theta} R_S(\mathcal{M})
    \le \frac{1}{\theta} \sqrt{\frac{2d}{m} \ln(em/d)}.
</script>
</div>
<p>我们带入到 Rademacher 复杂度的界可以得到：</p>
<div>
<div class="MathJax_Preview">
    \mathbf{Pr}_{\mathcal{S} \sim \mathcal{D}} \left\{
        \forall f \in co(\mathcal{H}):
        \mathbb{E}_{(x, y) \sim \mathcal{D}}[\phi(y f(x))]
        - \mathbb{E}_{(x, y) \sim \mathcal{S}}[\phi(y f(x))] \le
        R_S(\phi \circ \mathcal{M}) + 3 \sqrt{\frac{2}{m}\ln(2 / \delta)}
    \right\} \ge 1 - \delta.
</div>
<script type="math/tex; mode=display">
    \mathbf{Pr}_{\mathcal{S} \sim \mathcal{D}} \left\{
        \forall f \in co(\mathcal{H}):
        \mathbb{E}_{(x, y) \sim \mathcal{D}}[\phi(y f(x))]
        - \mathbb{E}_{(x, y) \sim \mathcal{S}}[\phi(y f(x))] \le
        R_S(\phi \circ \mathcal{M}) + 3 \sqrt{\frac{2}{m}\ln(2 / \delta)}
    \right\} \ge 1 - \delta.
</script>
</div>
<p>因为 <span><span class="MathJax_Preview">\pmb{1}\{u \le 0\} \le \phi(u) \le \pmb{1}\{u \le \theta\}</span><script type="math/tex">\pmb{1}\{u \le 0\} \le \phi(u) \le \pmb{1}\{u \le \theta\}</script></span>，所以我们有</p>
<div>
<div class="MathJax_Preview">
    \mathbf{Pr}_{(x, y) \sim \mathcal{D}}[y f(x) \le 0]
    = \mathbb{E}_{(x, y) \sim \mathcal{D}}[\pmb{1}\{y f(x) \le 0\}]
    \le \mathbb{E}_{(x, y) \sim \mathcal{D}} [\phi(y f(x))].
</div>
<script type="math/tex; mode=display">
    \mathbf{Pr}_{(x, y) \sim \mathcal{D}}[y f(x) \le 0]
    = \mathbb{E}_{(x, y) \sim \mathcal{D}}[\pmb{1}\{y f(x) \le 0\}]
    \le \mathbb{E}_{(x, y) \sim \mathcal{D}} [\phi(y f(x))].
</script>
</div>
<p>以及</p>
<div>
<div class="MathJax_Preview">
    \mathbb{E}_{(x, y) \sim \mathcal{S}} [\phi(y f(x))]
    \le \mathbb{E}_{(x, y) \sim \mathcal{S}}[\pmb{1}\{y f(x) \le 0\}]
    = \mathbf{Pr}_{(x, y) \sim \mathcal{S}}[y f(x) \le 0].
</div>
<script type="math/tex; mode=display">
    \mathbb{E}_{(x, y) \sim \mathcal{S}} [\phi(y f(x))]
    \le \mathbb{E}_{(x, y) \sim \mathcal{S}}[\pmb{1}\{y f(x) \le 0\}]
    = \mathbf{Pr}_{(x, y) \sim \mathcal{S}}[y f(x) \le 0].
</script>
</div>
<p>因此我们可得：</p>
<div>
<div class="MathJax_Preview">
    \mathbf{Pr}_{\mathcal{S} \sim \mathcal{D}} \left\{
        \forall f \in co(\mathcal{H}):
        \mathbf{Pr}_{(x, y) \sim \mathcal{D}}[y f(x) \le 0]
        - \mathbf{Pr}_{(x, y) \sim \mathcal{S}}[y f(x) \le \theta] \le
        \frac{2}{\theta} \sqrt{\frac{2d}{m} \ln(em/d)} 
        + 3 \sqrt{\frac{2}{m}\ln(2 / \delta)}
    \right\} \ge 1 - \delta.
</div>
<script type="math/tex; mode=display">
    \mathbf{Pr}_{\mathcal{S} \sim \mathcal{D}} \left\{
        \forall f \in co(\mathcal{H}):
        \mathbf{Pr}_{(x, y) \sim \mathcal{D}}[y f(x) \le 0]
        - \mathbf{Pr}_{(x, y) \sim \mathcal{S}}[y f(x) \le \theta] \le
        \frac{2}{\theta} \sqrt{\frac{2d}{m} \ln(em/d)} 
        + 3 \sqrt{\frac{2}{m}\ln(2 / \delta)}
    \right\} \ge 1 - \delta.
</script>
</div>
<p>通常我们将误差进一步近似为</p>
<div>
<div class="MathJax_Preview">
\begin{aligned}
    &amp;\frac{2}{\theta} \sqrt{\frac{2d}{m} \ln(em/d)} 
    + 3 \sqrt{\frac{2}{m}\ln(2 / \delta)} \\
    \approx&amp; \tilde{O} \bigg( \sqrt{\frac{d/\theta^2}{m}} \bigg) + 
    O\bigg( \sqrt{\ln(1 / \delta)}{m}\bigg) \\
    \approx&amp; \tilde{O} \bigg(\sqrt{\frac{d/\theta^2 + \ln(1/\delta)}{m}}\bigg).
\end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned}
    &\frac{2}{\theta} \sqrt{\frac{2d}{m} \ln(em/d)} 
    + 3 \sqrt{\frac{2}{m}\ln(2 / \delta)} \\
    \approx& \tilde{O} \bigg( \sqrt{\frac{d/\theta^2}{m}} \bigg) + 
    O\bigg( \sqrt{\ln(1 / \delta)}{m}\bigg) \\
    \approx& \tilde{O} \bigg(\sqrt{\frac{d/\theta^2 + \ln(1/\delta)}{m}}\bigg).
\end{aligned}
</script>
</div>
<h2 id="boosting-margin">Boosting 对 Margin 分布的影响<a class="headerlink" href="#boosting-margin" title="Permanent link">&para;</a></h2>
<p>前面的分析广泛适用于使用假设集 <span><span class="MathJax_Preview">co(\mathcal{H})</span><script type="math/tex">co(\mathcal{H})</script></span> 的算法，例如：投票分类算法（voting classifier）。这一节，我们分析一下 Boosting 的特别之处，总的来说就是通过给小margin样本更大的权重，来显著增大整个训练集的margin。</p>
<div class="admonition 定理3">
<p class="admonition-title">定理3</p>
<p>在 AdaBoost 中定义 <span><span class="MathJax_Preview">\gamma_t = \frac{1}{2} - \epsilon_t</span><script type="math/tex">\gamma_t = \frac{1}{2} - \epsilon_t</script></span>, 我们可以保证：
训练集中margin最多为 <span><span class="MathJax_Preview">\theta</span><script type="math/tex">\theta</script></span> 的样本个数占总样本个数的比例为：</p>
<div>
<div class="MathJax_Preview">
    \prod^T_{t=1} \sqrt{(1 + 2 \gamma_t)^{1 + \theta} (1 - 2 \gamma_t)^{1 - \theta}}.
</div>
<script type="math/tex; mode=display">
    \prod^T_{t=1} \sqrt{(1 + 2 \gamma_t)^{1 + \theta} (1 - 2 \gamma_t)^{1 - \theta}}.
</script>
</div>
</div>
<details class="证明"><summary>证明</summary><p>我们沿用定义 <span><span class="MathJax_Preview">f(x) = \frac{\sum^T_{t=1} \alpha_t h_t(x)}{\sum^T_{t=1} \alpha_t}</span><script type="math/tex">f(x) = \frac{\sum^T_{t=1} \alpha_t h_t(x)}{\sum^T_{t=1} \alpha_t}</script></span>，
那么 <span><span class="MathJax_Preview">y f(x) \le \theta</span><script type="math/tex">y f(x) \le \theta</script></span> 当且仅当 
<span><span class="MathJax_Preview">y \sum^T_{t=1} \alpha_t h_t(x) \le \theta \sum^T_{t=1} \alpha_t</span><script type="math/tex">y \sum^T_{t=1} \alpha_t h_t(x) \le \theta \sum^T_{t=1} \alpha_t</script></span>，
进一步当且仅当</p>
<div>
<div class="MathJax_Preview">
    \exp\left(
    -y \sum^T_{t=1} \alpha_t h_t(x)
    +\theta \sum^T_{t=1} \alpha_t    
    \right) \ge 1.
</div>
<script type="math/tex; mode=display">
    \exp\left(
    -y \sum^T_{t=1} \alpha_t h_t(x)
    +\theta \sum^T_{t=1} \alpha_t    
    \right) \ge 1.
</script>
</div>
<p>因此</p>
<div>
<div class="MathJax_Preview">
    \pmb{1} [y f(x) \le \theta] \le
    \exp\left(
    -y \sum^T_{t=1} \alpha_t h_t(x)
    +\theta \sum^T_{t=1} \alpha_t    
    \right).
</div>
<script type="math/tex; mode=display">
    \pmb{1} [y f(x) \le \theta] \le
    \exp\left(
    -y \sum^T_{t=1} \alpha_t h_t(x)
    +\theta \sum^T_{t=1} \alpha_t    
    \right).
</script>
</div>
<p>所以，我们可得</p>
<div>
<div class="MathJax_Preview">
\begin{aligned}
    &amp;\mathbf{Pr}_{(x, y) \sim S} [y f(x) \le \theta]
    = \frac{1}{m} \sum^m_{i=1} \pmb{1}[y_i f(x_i) \le \theta]\\
    \le&amp; \frac{1}{m}
        \exp\left(
        -y \sum^T_{t=1} \alpha_t h_t(x)
        +\theta \sum^T_{t=1} \alpha_t    
        \right)\\
    =&amp; \frac{1}{m} \exp\left(\theta \sum^T_{t=1} \alpha_t \right)
        \sum^m_{i=1} \exp\left(-y_i \sum^T_{t=1} \alpha_t h_t(x_i)\right)\\
    =&amp; \exp\left(\theta \sum^T_{t=1} \alpha_t \right) \prod^T_{t=1} Z_t\\
    =&amp; \prod^{T}_{t=1} e^{\theta \alpha_t} Z_t\\
    =&amp; \prod^{T}_{t=1} \bigg[2 \sqrt{\epsilon^{1-\theta}_t (1 - \epsilon_t)^{1+\theta}}\bigg]\\
    &amp;\quad \bigg(\alpha_t = \frac{1}{2} \ln \frac{1 - \epsilon_t}{\epsilon_t}, Z_t=2\sqrt{\epsilon_t(1 - \epsilon_t)} \bigg)\\
    =&amp; \prod^{T}_{t=1} \bigg[(1 - 2 \gamma_t)^{1 - \theta} (1 + 2\gamma_t)^{1+\theta}\bigg]. \quad \bigg(\epsilon_t = \frac{1}{2} - \gamma_t\bigg)
\end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned}
    &\mathbf{Pr}_{(x, y) \sim S} [y f(x) \le \theta]
    = \frac{1}{m} \sum^m_{i=1} \pmb{1}[y_i f(x_i) \le \theta]\\
    \le& \frac{1}{m}
        \exp\left(
        -y \sum^T_{t=1} \alpha_t h_t(x)
        +\theta \sum^T_{t=1} \alpha_t    
        \right)\\
    =& \frac{1}{m} \exp\left(\theta \sum^T_{t=1} \alpha_t \right)
        \sum^m_{i=1} \exp\left(-y_i \sum^T_{t=1} \alpha_t h_t(x_i)\right)\\
    =& \exp\left(\theta \sum^T_{t=1} \alpha_t \right) \prod^T_{t=1} Z_t\\
    =& \prod^{T}_{t=1} e^{\theta \alpha_t} Z_t\\
    =& \prod^{T}_{t=1} \bigg[2 \sqrt{\epsilon^{1-\theta}_t (1 - \epsilon_t)^{1+\theta}}\bigg]\\
    &\quad \bigg(\alpha_t = \frac{1}{2} \ln \frac{1 - \epsilon_t}{\epsilon_t}, Z_t=2\sqrt{\epsilon_t(1 - \epsilon_t)} \bigg)\\
    =& \prod^{T}_{t=1} \bigg[(1 - 2 \gamma_t)^{1 - \theta} (1 + 2\gamma_t)^{1+\theta}\bigg]. \quad \bigg(\epsilon_t = \frac{1}{2} - \gamma_t\bigg)
\end{aligned}
</script>
</div>
<p>其中一个等式用到了<span><span class="MathJax_Preview">\prod^{T}_{t=1}Z_t</span><script type="math/tex">\prod^{T}_{t=1}Z_t</script></span>，特此证明一下。我们回忆一下Adaboost里</p>
<div>
<div class="MathJax_Preview">
\begin{aligned}
    D_{T+1}(i) 
    &amp;= D_1(i) \times \frac{e^{-y_i \alpha_1 h_1(x_i)}}{Z_1} \times \cdots \times
    \frac{e^{-y_i\alpha_T h_T(x_i)}}{Z_T}\\
    &amp;= \frac{1}{m} \frac{\exp{\left(-y_i \sum^T_{t=1} \alpha_t h_t(x_i)\right)}}{\prod^T_{t=1} Z_t}.
\end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned}
    D_{T+1}(i) 
    &= D_1(i) \times \frac{e^{-y_i \alpha_1 h_1(x_i)}}{Z_1} \times \cdots \times
    \frac{e^{-y_i\alpha_T h_T(x_i)}}{Z_T}\\
    &= \frac{1}{m} \frac{\exp{\left(-y_i \sum^T_{t=1} \alpha_t h_t(x_i)\right)}}{\prod^T_{t=1} Z_t}.
\end{aligned}
</script>
</div>
<p>所以 </p>
<div>
<div class="MathJax_Preview">
    {\prod^T_{t=1} Z_t}
    ={\prod^T_{t=1} Z_t} \sum^m_{i=1} D_{T+1}(i) 
    = \frac{1}{m} \sum^m_{i=1} \exp{\left(-y_i \sum^T_{t=1} \alpha_t h_t(x_i)\right)}.
</div>
<script type="math/tex; mode=display">
    {\prod^T_{t=1} Z_t}
    ={\prod^T_{t=1} Z_t} \sum^m_{i=1} D_{T+1}(i) 
    = \frac{1}{m} \sum^m_{i=1} \exp{\left(-y_i \sum^T_{t=1} \alpha_t h_t(x_i)\right)}.
</script>
</div>
</details>
<p>如果 <span><span class="MathJax_Preview">\epsilon_t \le \frac{1}{2} - \gamma</span><script type="math/tex">\epsilon_t \le \frac{1}{2} - \gamma</script></span>, 那么界就变成了
<span><span class="MathJax_Preview">\left(\sqrt{(1 + 2 \gamma)^{1 + \theta} (1 - 2 \gamma)^{1 - \theta}}\right)^T</span><script type="math/tex">\left(\sqrt{(1 + 2 \gamma)^{1 + \theta} (1 - 2 \gamma)^{1 - \theta}}\right)^T</script></span>。
如果 <span><span class="MathJax_Preview">\sqrt{(1 + 2 \gamma)^{1 + \theta} (1 - 2 \gamma)^{1 - \theta}} &lt; 1</span><script type="math/tex">\sqrt{(1 + 2 \gamma)^{1 + \theta} (1 - 2 \gamma)^{1 - \theta}} < 1</script></span>，
那么随着 AdaBoost 的轮次增加，<span><span class="MathJax_Preview">yf(x) \le \theta</span><script type="math/tex">yf(x) \le \theta</script></span> 的可能指数下降到0。
我们整理一下得到：</p>
<div>
<div class="MathJax_Preview">
    \theta &lt; \Upsilon(\gamma) = \frac{-\ln(1 - 4\gamma^2)}
    {\ln\left(\frac{1 + 2 \gamma}{ 1 - 2 \gamma}\right)}.
</div>
<script type="math/tex; mode=display">
    \theta < \Upsilon(\gamma) = \frac{-\ln(1 - 4\gamma^2)}
    {\ln\left(\frac{1 + 2 \gamma}{ 1 - 2 \gamma}\right)}.
</script>
</div>
<p>因为 <span><span class="MathJax_Preview">0 \le \gamma \le \frac{1}{2}</span><script type="math/tex">0 \le \gamma \le \frac{1}{2}</script></span>，所以我们得到 <span><span class="MathJax_Preview">\gamma \le \Upsilon(\gamma) \le 2 \gamma</span><script type="math/tex">\gamma \le \Upsilon(\gamma) \le 2 \gamma</script></span>。 而且，当 <span><span class="MathJax_Preview">\gamma</span><script type="math/tex">\gamma</script></span> 接近0时，<span><span class="MathJax_Preview">\Upsilon(\gamma) \approx \gamma</span><script type="math/tex">\Upsilon(\gamma) \approx \gamma</script></span>。所以经过一定轮数，<span><span class="MathJax_Preview">\Upsilon(\gamma)</span><script type="math/tex">\Upsilon(\gamma)</script></span> 给了一定的界保障了 margin。 <span><span class="MathJax_Preview">\gamma_t</span><script type="math/tex">\gamma_t</script></span> 越大，margin越大。这里通常将 <span><span class="MathJax_Preview">\gamma_t</span><script type="math/tex">\gamma_t</script></span> 称为 edge。这里有点博弈的意味：更强的基础分类器能保证 edge 更大，margin也越大，能够避免过拟合。但是更强的基础分类器也会导致的复杂度增加（Rademacher复杂度大），也会对算法的效果有负面影响。</p>
<h2 id="marginboosting">Margin最大化Boosting<a class="headerlink" href="#marginboosting" title="Permanent link">&para;</a></h2>
<p>上一节证明了，在原始的AdaBoost中，Margin由<span><span class="MathJax_Preview">\Upsilon(\gamma)</span><script type="math/tex">\Upsilon(\gamma)</script></span>限制。而<span><span class="MathJax_Preview">\Upsilon(\gamma)</span><script type="math/tex">\Upsilon(\gamma)</script></span>在<span><span class="MathJax_Preview">\gamma</span><script type="math/tex">\gamma</script></span>趋近于0时，满足<span><span class="MathJax_Preview">\Upsilon(\gamma) \approx \gamma</span><script type="math/tex">\Upsilon(\gamma) \approx \gamma</script></span>。<span><span class="MathJax_Preview">\gamma</span><script type="math/tex">\gamma</script></span>这个界太小了，本节提出一种AdaBoost的变种，将会提高这个结果到<span><span class="MathJax_Preview">2\gamma</span><script type="math/tex">2\gamma</script></span>。</p>
<p>在AdaBoost中，有关系</p>
<div>
<div class="MathJax_Preview">
Z_t = e^{-\alpha_t} \bigg(\frac{1}{2} + \gamma_t\bigg) + e^{\alpha_t} \bigg( \frac{1}{2} - \gamma_t\bigg).
</div>
<script type="math/tex; mode=display">
Z_t = e^{-\alpha_t} \bigg(\frac{1}{2} + \gamma_t\bigg) + e^{\alpha_t} \bigg( \frac{1}{2} - \gamma_t\bigg).
</script>
</div>
<p>带入上节的一个等式可得</p>
<div>
<div class="MathJax_Preview">
\mathbb{Pr}_{(x, y)\sim \mathcal{S}} [y f(x) \le \theta]
\le \prod^{T}_{t=1} \bigg[e^{(\theta-1)\alpha_t}(\frac{1}{2} + \gamma_t) + e^{(\theta+1) \alpha_t} (\frac{1}{2} - \gamma_t)\bigg].
</div>
<script type="math/tex; mode=display">
\mathbb{Pr}_{(x, y)\sim \mathcal{S}} [y f(x) \le \theta]
\le \prod^{T}_{t=1} \bigg[e^{(\theta-1)\alpha_t}(\frac{1}{2} + \gamma_t) + e^{(\theta+1) \alpha_t} (\frac{1}{2} - \gamma_t)\bigg].
</script>
</div>
<p>那么，我们为什么不最小化上面的margin的界呢？对<span><span class="MathJax_Preview">\alpha_t</span><script type="math/tex">\alpha_t</script></span>求极值可得</p>
<div>
<div class="MathJax_Preview">
\alpha^*_t = \frac{1}{2}\ln\frac{1+2\gamma_t}{1-2\gamma_t} - \frac{1}{2} \ln\frac{1 + \theta}{1 - \theta}.
</div>
<script type="math/tex; mode=display">
\alpha^*_t = \frac{1}{2}\ln\frac{1+2\gamma_t}{1-2\gamma_t} - \frac{1}{2} \ln\frac{1 + \theta}{1 - \theta}.
</script>
</div>
<p>如果我们提前取 <span><span class="MathJax_Preview">\theta</span><script type="math/tex">\theta</script></span> 满足 <span><span class="MathJax_Preview">\gamma_t \ge \theta/2</span><script type="math/tex">\gamma_t \ge \theta/2</script></span>，那么<span><span class="MathJax_Preview">\alpha^*_t \ge 0</span><script type="math/tex">\alpha^*_t \ge 0</script></span>。经过一些复杂的缩放，我们可以得到一个简洁的界（我没有验证过，书上也是跳过了这个证明）</p>
<div>
<div class="MathJax_Preview">
\mathbb{Pr}_{(x, y)\sim \mathcal{S}} [y f(x) \le \theta]
\le \exp\bigg[- \sum^T_{t=1} \mathrm{RE}_{b}\bigg(\frac{1}{2}+\frac{\theta}{2} \bigg\Vert \frac{1}{2} + \gamma_t\bigg)\bigg].
</div>
<script type="math/tex; mode=display">
\mathbb{Pr}_{(x, y)\sim \mathcal{S}} [y f(x) \le \theta]
\le \exp\bigg[- \sum^T_{t=1} \mathrm{RE}_{b}\bigg(\frac{1}{2}+\frac{\theta}{2} \bigg\Vert \frac{1}{2} + \gamma_t\bigg)\bigg].
</script>
</div>
<p>其中<span><span class="MathJax_Preview">\mathrm{RE}_b(p \Vert q)</span><script type="math/tex">\mathrm{RE}_b(p \Vert q)</script></span>表示两个伯努利分布的相对熵</p>
<div>
<div class="MathJax_Preview">
\mathrm{RE}_b(p \Vert q) = p \ln\frac{p}{q} + (1 - p) \ln\frac{1 - p}{1 - q}.
</div>
<script type="math/tex; mode=display">
\mathrm{RE}_b(p \Vert q) = p \ln\frac{p}{q} + (1 - p) \ln\frac{1 - p}{1 - q}.
</script>
</div>
<p>如果提前确定了 <span><span class="MathJax_Preview">\theta</span><script type="math/tex">\theta</script></span> 并且 <span><span class="MathJax_Preview">\gamma</span><script type="math/tex">\gamma</script></span>-弱分类假设中 <span><span class="MathJax_Preview">\gamma &gt; \theta_2</span><script type="math/tex">\gamma > \theta_2</script></span>，那么训练集的关于margin界的误差率不大于</p>
<div>
<div class="MathJax_Preview">
\exp\bigg[- T \cdot \mathrm{RE}_{b}\bigg(\frac{1}{2}+\frac{\theta}{2} \bigg\Vert \frac{1}{2} + \gamma\bigg)\bigg].
</div>
<script type="math/tex; mode=display">
\exp\bigg[- T \cdot \mathrm{RE}_{b}\bigg(\frac{1}{2}+\frac{\theta}{2} \bigg\Vert \frac{1}{2} + \gamma\bigg)\bigg].
</script>
</div>
<p>反之，如果提前知道了 <span><span class="MathJax_Preview">\gamma</span><script type="math/tex">\gamma</script></span>，那么 <span><span class="MathJax_Preview">\theta</span><script type="math/tex">\theta</script></span> 可以取得比 <span><span class="MathJax_Preview">2\gamma</span><script type="math/tex">2\gamma</script></span> 略小一些。</p>
<p>理论很丰满，现实很骨感。我们通常不能获得 <span><span class="MathJax_Preview">\gamma</span><script type="math/tex">\gamma</script></span> 或者 <span><span class="MathJax_Preview">\theta</span><script type="math/tex">\theta</script></span> 的信息，只能通过不断调整<span><span class="MathJax_Preview">\theta</span><script type="math/tex">\theta</script></span>来得到类似的界，如算法 <span><span class="MathJax_Preview">arc-gv</span><script type="math/tex">arc-gv</script></span> 或者 <span><span class="MathJax_Preview">AdaBoost^*_\nu</span><script type="math/tex">AdaBoost^*_\nu</script></span>（我也不知道具体细节，但是应该没关系）。设置 <span><span class="MathJax_Preview">\theta</span><script type="math/tex">\theta</script></span> 的目的本意是为了增加泛化性，但是实践中，这些算法往往会失败。第一个原因是 margin 设置得高，还要保持错误率低，就需要基础分类器的复杂度非常高（例如决策树的树的深度和宽度会非常大），样本需求就越来越大。 我们往往没有那么多样本，就导致了算法的失败。另一方面，使用表达能力较差的分类器（如 decision stumps）同样也会导致无法提升 AdaBoost。虽然它提高了最小的margin，但是付出的代价可能是大部分其他样本的margin降低，整体来看，margin其实还是降低的。而泛化误差的界是和整体的margin有关，而不是最小的margin。</p>
<h2 id="weak-learnability">Weak Learnability 的充分必要条件<a class="headerlink" href="#weak-learnability" title="Permanent link">&para;</a></h2>
<h3 id="_1">充分条件<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h3>
<p>充分条件是对于所有的样本 <span><span class="MathJax_Preview">(x_i, y_i) \in \mathcal{S}</span><script type="math/tex">(x_i, y_i) \in \mathcal{S}</script></span>，弱分类器 <span><span class="MathJax_Preview">g_1, \ldots, g_k</span><script type="math/tex">g_1, \ldots, g_k</script></span> 存在凸组合分类器满足</p>
<div>
<div class="MathJax_Preview">
    y_i \sum^{k}_{j=1} a_j g_j(x_i) \ge \theta.
</div>
<script type="math/tex; mode=display">
    y_i \sum^{k}_{j=1} a_j g_j(x_i) \ge \theta.
</script>
</div>
<p>那么对于任意定义在训练集 <span><span class="MathJax_Preview">\mathcal{S}</span><script type="math/tex">\mathcal{S}</script></span> 上的分布 <span><span class="MathJax_Preview">\mathcal{D}</span><script type="math/tex">\mathcal{D}</script></span> 都有</p>
<div>
<div class="MathJax_Preview">
    \sum^{k}_{j=1} \alpha_j \mathbb{E}_{i \sim\mathcal{D}} [y_i g_j(x_i)] = \mathbb{E}_{i \sim \mathcal{D}} \bigg[y_i \sum^{k}_{j=1} a_j g_j(x_i)\bigg] \ge \theta.
</div>
<script type="math/tex; mode=display">
    \sum^{k}_{j=1} \alpha_j \mathbb{E}_{i \sim\mathcal{D}} [y_i g_j(x_i)] = \mathbb{E}_{i \sim \mathcal{D}} \bigg[y_i \sum^{k}_{j=1} a_j g_j(x_i)\bigg] \ge \theta.
</script>
</div>
<p>又因为</p>
<div>
<div class="MathJax_Preview">
\begin{aligned}
    \mathbb{E}_{i \sim \mathcal{D}} [y_i g_j(x_i)] =&amp; 
    1 \cdot \mathbf{Pr}_{i \sim \mathcal{D}}[y_i = g_j(x_i)] + (-1) \cdot \mathbf{Pr}_{i \sim \mathcal{D}} [y_i \ne g_j(x_i)]\\
    =&amp; 1 - 2 \mathbf{Pr}_{i \sim \mathcal{D}} [y_i \ne g_j(x_i)],
\end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathbb{E}_{i \sim \mathcal{D}} [y_i g_j(x_i)] =& 
    1 \cdot \mathbf{Pr}_{i \sim \mathcal{D}}[y_i = g_j(x_i)] + (-1) \cdot \mathbf{Pr}_{i \sim \mathcal{D}} [y_i \ne g_j(x_i)]\\
    =& 1 - 2 \mathbf{Pr}_{i \sim \mathcal{D}} [y_i \ne g_j(x_i)],
\end{aligned}
</script>
</div>
<p>所以</p>
<div>
<div class="MathJax_Preview">
    \mathbf{Pr}_{i \sim \mathcal{D}}[y_i \ne g_j(x_i)] \le \frac{1}{2} - \frac{\theta}{2}.
</div>
<script type="math/tex; mode=display">
    \mathbf{Pr}_{i \sim \mathcal{D}}[y_i \ne g_j(x_i)] \le \frac{1}{2} - \frac{\theta}{2}.
</script>
</div>
<p>所以，弱分类器的一个充分条件是，在样本是线性可分的，并且线性分类的margin至少为 <span><span class="MathJax_Preview">2\gamma</span><script type="math/tex">2\gamma</script></span>。</p>
<h3 id="_2">必要条件<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h3>
<p>上面的 <span><span class="MathJax_Preview">2\gamma</span><script type="math/tex">2\gamma</script></span>-线性可分条件也是必要条件。</p>
                
                  
                    

<hr>
<div class="md-source-date">
  <small>
    
      最后更新: <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">2020年12月30日</span>
    
  </small>
</div>
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid" aria-label="Footer">
        
          <a href="../12-GenerationsOfBoosting/" title="Generation Of Boosting" class="md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
            </div>
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  上一页
                </span>
                Generation Of Boosting
              </div>
            </div>
          </a>
        
        
          <a href="../14-GameTheory/" title="Game Theory, Online Learning and Boosting" class="md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  下一页
                </span>
                Game Theory, Online Learning and Boosting
              </div>
            </div>
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../assets/javascripts/vendor.92ffa368.min.js"></script>
      <script src="../../assets/javascripts/bundle.5123e3d4.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "\u590d\u5236", "clipboard.copied": "\u5df2\u590d\u5236", "search.config.lang": "ja", "search.config.pipeline": "trimmer, stemmer", "search.config.separator": "[\\uff0c\\u3002]+", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c"}</script>
      
      <script>
        app = initialize({
          base: "../..",
          features: [],
          search: Object.assign({
            worker: "../../assets/javascripts/worker/search.a68abb33.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>